{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490c35bd-437e-477b-939b-989c96f8df47",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f01593-9f4e-454b-a853-6f34b8ea27b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbf5bf-630d-43b0-a2e1-7fa32918be0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98f61978-dc00-48ec-8431-7bf347917653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb94acc0-6a39-4d6b-8c83-68b324541080",
   "metadata": {},
   "source": [
    "### Create functions for all steps involved in complete model training lifecycle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88013a6e-cf87-43ce-9fee-38bc88e78f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_data(path):\n",
    "    return pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fc86ec-098b-4f96-bf0f-960b12fff061",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = load_data(\"https://raw.githubusercontent.com/TripathiAshutosh/dataset/main/banking.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f9684e-c309-4323-8a0d-89f7c5798922",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_cleaning(data):\n",
    "    print('na values available in data\\n')\n",
    "    print(data.isna().sum())\n",
    "    data = data.dropna()\n",
    "    print('After dropping na values \\n')\n",
    "    print(data.isna().sum())\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63cb92e-f8dd-4df3-b39a-500e95e1c490",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    data['education'] = np.where(data['education'] =='basic.9y', 'Basic', data['education'])\n",
    "    data['education'] = np.where(data['education'] == 'basic.6y', 'Basic', data['education'])\n",
    "    data['education'] = np.where(data['education'] == 'basic.4y', 'Basic', data['education'])\n",
    "    \n",
    "    cat_vars = ['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact', 'month', 'day_of_week', 'poutcome']\n",
    "    for var in cat_vars:\n",
    "        cat_list = 'var'+ '_' + var\n",
    "        cat_list = pd.get_dummies(data[var], prefix=var)\n",
    "        data1 = data.join(cat_list)\n",
    "        data = data1\n",
    "        \n",
    "    data_vars = data.columns.values.tolist()\n",
    "    to_keep = [i for i in data_vars if i not in cat_vars]\n",
    "    final_data = data[to_keep]\n",
    "    \n",
    "    final_data.columns = final_data.columns.str.replace(\".\", \"_\")\n",
    "    final_data.columns = final_data.columns.str.replace(\" \", \"_\")\n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6255f0c-a0aa-4c67-9e38-16d0d168ee5b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def df_train_test_split(final_data):\n",
    "    X = final_data.loc[:, final_data.columns != 'y']\n",
    "    y = final_data.loc[:, final_data.columns == 'y']\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, stratify=y, random_state=47)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff1372-f895-4198-9d39-8a3474319872",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def over_sampling_target_class(X_train, y_train):\n",
    "    from imblearn.over_sampling import SMOTE\n",
    "    os = SMOTE(random_state=0)\n",
    "    \n",
    "    columns = X_train.columns\n",
    "    os_data_X, os_data_y = os.fit_resample(X_train, y_train)\n",
    "    \n",
    "    os_data_X = pd.DataFrame(data=os_data_X, columns=columns)\n",
    "    os_data_y = pd.DataFrame(data=os_data_y, columns=['y'])\n",
    "    print(\"length of over-sampled data is:\", len(os_data_X))\n",
    "    print(\"length of no subscription in oversampled data\", len(os_data_y[os_data_y['y']==0]))\n",
    "    print(\"Number of subscription\", len(os_data_y[os_data_y[\"y\"]==1]))\n",
    "    print(\"Proportion of no subscription data in oversampled data is\", len(os_data_y[os_data_y['y']==0])/len(os_data_X))\n",
    "    print(\"Proportion of subscription data in oversampled data is\", len(os_data_y[os_data_y['y']==1])/len(os_data_X))\n",
    "    \n",
    "    X_train = os_data_X\n",
    "    y_train = os_data_y['y']\n",
    "    \n",
    "    return X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cdab17-c802-4385-871d-e6cbfc74a9e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def training_basic_classifier(X_train, y_train):\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=100)\n",
    "    return model.fit(X_train, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b712652e-bcd4-4a61-b56b-ffb44d372312",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_on_test_data(model, X_test):\n",
    "    return model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d26bb7f-7baf-4526-888b-392ef46a0257",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_prob_on_test_data(model, X_test):\n",
    "    return model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01986443-873d-4bcb-b8e8-8a33b1ef05f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_metrics(y_true, y_pred, y_pred_proba):\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, log_loss\n",
    "    acc= accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    entropy = log_loss(y_true, y_pred_proba)\n",
    "    return {'accuracy': round(acc, 2), 'precision': round(prec, 2), 'recall': round(recall, 2), 'entropy': round(entropy, 2)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f3454-0656-4f70-a343-76a2b0940ceb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_roc_auc_plot(clf, X_data, y_data):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn import metrics\n",
    "    metrics.plot_roc_curve(clf, X_data, y_data)\n",
    "    plt.savefig('roc_auc_curve.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac73de72-bd99-4b4a-8487-841773107124",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_confusion_metrics_plot(clf, X_test, y_test):\n",
    "    import matplotlib.pyplot as plt\n",
    "    from sklearn.metrics import plot_confusion_matrix\n",
    "    plot_confusion_matrix(clf, X_test, y_test)\n",
    "    plt.savefig('confusion_matrix.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ebdaf11-9b09-4225-8cda-11290db2eef4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hyper_parameter_tuning(X_train, y_train):\n",
    "    n_estimators = [5, 21, 51, 101]\n",
    "    max_features = ['auto', 'sqrt']\n",
    "    max_depth = [int(x) for x in np.linspace(10, 120, num=12)]\n",
    "    min_samples_split = [2,  6, 10]\n",
    "    min_samples_leaf = [1, 3, 4]\n",
    "    bootstrap = [True, False]\n",
    "    \n",
    "    random_grid = {'n_estimators': n_estimators,\n",
    "                  'max_features': max_features,\n",
    "                  'max_depth': max_depth,\n",
    "                  'min_samples_split': min_samples_split,\n",
    "                  'min_samples_leaf': min_samples_leaf,\n",
    "                  'bootstrap': bootstrap\n",
    "                  }\n",
    "    \n",
    "    from sklearn.model_selection import RandomizedSearchCV\n",
    "    from sklearn.ensemble import RandomForestClassifier\n",
    "    classifier = RandomForestClassifier()\n",
    "    model_tuning = RandomizedSearchCV(estimator = classifier, param_distributions=random_grid, \n",
    "                                     n_iter = 100, cv=5, verbose=2, random_state=35, n_jobs=-1\n",
    "                                    )\n",
    "    model_tuning.fit(X_train, y_train)\n",
    "    print(\"Random Grid:\", random_grid, '\\n')\n",
    "    \n",
    "    print('Best Parameters:', model_tuning.best_params_, '\\n')\n",
    "    best_params = model_tuning.best_params_\n",
    "    \n",
    "    n_estimators = best_params['n_estimators']\n",
    "    min_samples_split = best_params['min_samples_split']\n",
    "    min_samples_leaf = best_params['min_samples_leaf']\n",
    "    max_features = best_params['max_features']\n",
    "    max_depth = best_params['max_depth']\n",
    "    bootstrap = best_params['bootstrap']\n",
    "    \n",
    "    model_tuned= RandomForestClassifier(n_estimators = n_estimators, min_samples_split = min_samples_split,\n",
    "                                        min_samples_leaf= min_samples_leaf, max_features=max_features,\n",
    "                                        max_depth=max_depth, bootstrap=bootstrap)\n",
    "    model_tuned.fit(X_train, y_train)\n",
    "    return model_tuned, best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6a8c00-89bc-419f-81d2-a60ed6ebead5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cleaned_data = data_cleaning(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a478e5b8-4236-4987-94d4-7cd19bfb957b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "final_data = preprocessing(cleaned_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9918f9f-3aa2-42d1-8f57-e9dab5bea76f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = df_train_test_split(final_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d87a0bc-3816-43a9-b23c-ab1e686a4aa1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train, y_train = over_sampling_target_class(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860ec353-90f4-4325-909b-c6a817a08e00",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = training_basic_classifier(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b423028-8c61-4646-8f34-31fb21728662",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred = predict_on_test_data(model=model, X_test=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1af8b93-ab61-4274-9bc9-ad6b7a4adcb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3dc359-9780-4c7c-8916-650650a7c904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_prob = predict_prob_on_test_data(model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84096c57-fb6e-48f3-8c6b-ee70832a50b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_pred_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abf9871-9031-4fa8-95dc-aa226337c74f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824d7ddf-be78-46bf-8590-7778702bbbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(run_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2350ac6b-5561-4b6c-a6f2-021ddb724b48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_roc_auc_plot(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865f77ba-786e-4416-9a11-24f63724480a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_confusion_metrics_plot(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020e29d6-6403-483d-9fb3-d9f7b30c901a",
   "metadata": {},
   "source": [
    "## ML FLow work Starts from here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc91f96-7bea-4e7e-8b5b-fcce638ee40a",
   "metadata": {},
   "source": [
    "### Functions to create an experiment in MLFlow and log parameters, metrics and artifacts files like images etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f12220-ca6b-4d66-af3c-1140e44dfd38",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_experiment(experiment_name, run_name, run_metrics, model, confusion_matrix_path=None, \n",
    "                     roc_auc_plot_path=None, run_params=None):\n",
    "    import mlflow\n",
    "    mlflow.set_tracking_uri(\"http://localhost:8000\") # Document this line if you want to use any database like sqlite\n",
    "    mlflow.set_experiment(experiment_name)\n",
    "    \n",
    "    with mlflow.start_run():\n",
    "        \n",
    "        if not run_params == None:\n",
    "            for param in run_params:\n",
    "                mlflow.log_param(param, run_params[param])\n",
    "        \n",
    "        for metric in run_metrics:\n",
    "            mlflow.log_metric(metric, run_metrics[metric])\n",
    "        \n",
    "        mlflow.sklearn.log_model(model, \"model\")\n",
    "        \n",
    "        if not confusion_matrix_path == None:\n",
    "            mlflow.log_artifact(confusion_matrix_path, 'confusion_matrix')\n",
    "        \n",
    "        if not roc_auc_plot_path == None:\n",
    "            mlflow.log_artifact(roc_auc_plot_path, \"roc_auc_plot\")\n",
    "        \n",
    "        mlflow.set_tag(\"tag1\", \"RandomForest\")\n",
    "        mlflow.set_tags({\"tag2\": \"Randomized Search CV\", \"tag3\": \"Production\"})\n",
    "    \n",
    "    print(\"Run - %s is logged to Experiment - %s\" %(run_name, experiment_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a1e281-f49d-4e05-8539-bd06ee088d17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "experiment_name = \"Experiment_1\"\n",
    "run_name = \"term_deposit\"\n",
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)\n",
    "print(run_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ff91b-11e5-4e1c-8d5b-eb70e3a3ad1c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_experiment(experiment_name, run_name, run_metrics, model, 'confusion_matrix.png', 'roc_auc_curve.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc12abf-cbb7-44d5-8e28-a97c9927a930",
   "metadata": {},
   "source": [
    "## Create another experiment after tuning hyperparameters and log the best set of parameters fow which model gives the optimal performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453ff7af-99a0-4be4-9e7d-7e14c6ba5e18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import mlflow\n",
    "experiment_name = \"optimized model\"\n",
    "run_name = \"Random_Search_CV_Tuned_Model\"\n",
    "\n",
    "model_tuned, best_params = hyper_parameter_tuning(X_train, y_train)\n",
    "run_params = best_params\n",
    "\n",
    "y_pred = predict_on_test_data(model_tuned, X_test)\n",
    "y_pred_prob = predict_prob_on_test_data(model_tuned, X_test)\n",
    "run_metrics = get_metrics(y_test, y_pred, y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b886d5-a54a-47c8-87a8-70324c987dbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "run_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3404101-9b5d-4251-a9d6-53513bbfdec4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for param in run_params:\n",
    "    print(param, run_params[param])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74827dcc-bf37-492a-b701-4e1446a1676f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "create_experiment(experiment_name, run_name, run_metrics, model_tuned, 'confusion_matrix.png', 'roc_auc_curve.png', run_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f051d05-53b2-4ad1-981d-93f19938d771",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
